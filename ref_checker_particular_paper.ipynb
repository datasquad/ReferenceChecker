{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04e53054",
   "metadata": {},
   "source": [
    "# Student submission reference checker\n",
    "\n",
    "This code will cycle through all pdf files in a folder (presumably student assignment submissions), identify the references and check whether the references are real or hallucination. This process requires a little confidence in installing softwares and a little familiarity with Terminals.\n",
    "\n",
    "## Setup\n",
    "\n",
    "The software used to extract references is  called [GROBIT](https://grobid.readthedocs.io/en/latest/) which stands for \"GeneRation Of BIbliographic Data\".\n",
    "\n",
    "The GROBIT software is delivered via [Docker](https://www.docker.com/) on your computer. \n",
    "\n",
    "### Installing and Testing Docker\n",
    "\n",
    "Go to [Docker](https://www.docker.com/) to download the Desktop version of Docker that fits your operating system. In my case that was the Windows AMD64 version. Once you downloaded the Docker software to your computer you should go to your Terminal and use the following two commands.\n",
    "\n",
    "``` bash\n",
    "docker --version\n",
    "docker run hello-world\n",
    "```\n",
    "\n",
    "They should give you the version of Docker you have installed and successfully run the short `hello-world` script.\n",
    "\n",
    "### Installing and Testing GROBIT\n",
    "\n",
    "This software uses some pre-trained artificial intelligence engine to extract, from a piece of text, the bibliographic information for the references used.\n",
    "\n",
    "Now you need to install and run the [GROBIT](https://grobid.readthedocs.io/en/latest/) application. The full guidance is available [here](https://grobid.readthedocs.io/en/latest/getting_started/).\n",
    "\n",
    "In your Terminal run\n",
    "\n",
    "``` bash\n",
    "docker pull grobid/grobid:0.8.2.1-crf\n",
    "```\n",
    "\n",
    "This basically loads the software. You can then start it with the following \n",
    "\n",
    "``` bash\n",
    "docker run --rm --init --ulimit core=0 -p 8070:8070 grobid/grobid:0.8.2.1-crf\n",
    "```\n",
    "\n",
    "If you now open your Docker Desktop you can see the an instance, or a container, with the GROBIT software running.\n",
    "\n",
    "![Docker Desktop](Docker_image1.png)\n",
    "\n",
    "If you click on the port, then a browser will open with the following \n",
    "\n",
    "![Grobit](Grobit_image1.png)\n",
    "\n",
    "Here you can go to the **PDF** tab and upload a PDF document. It highlights the references and the can create hyperlinks to the detected references.\n",
    "\n",
    "You can close that application by clicking on the stop button in the Docker Desktop.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7e60b5",
   "metadata": {},
   "source": [
    "## Workflow\n",
    "\n",
    "Before you run the code you need to make sure to have the GROBIT container open as described above (starting Gorbit desktop and then running the two commands above). `GROBID_URL` refers to that open container. \n",
    "\n",
    "Parameters to set:\n",
    "\n",
    "1. `PDF_FOLDER`, this is the path to the folder in which the pdf submissions are saved.\n",
    "2. `GROBID_URL `, this is the path to the instance in which GROBIT runs. YOu can get it by copying the url you get when you click on the relevant Port in the Docker Desktop (see above)\n",
    "\n",
    "The output will be saved into the source directory of this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63623e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import List, Optional, Dict, Any, Tuple\n",
    "from weakref import ref\n",
    "\n",
    "import requests\n",
    "from lxml import etree\n",
    "from rapidfuzz import fuzz\n",
    "from tqdm import tqdm\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "PDF_FOLDER = \"C:/Temp/YAWYR2/test_file\"\n",
    "GROBID_URL = \"http://localhost:8070/api/processReferences\"\n",
    "\n",
    "# Verification APIs\n",
    "CROSSREF_WORKS = \"https://api.crossref.org/works\"\n",
    "OPENALEX_WORKS = \"https://api.openalex.org/works\"\n",
    "\n",
    "# Heuristics / thresholds\n",
    "TITLE_MATCH_THRESHOLD = 85      # fuzzy title match\n",
    "MIN_EVIDENCE_SCORE = 3          # how many checks must pass to call it \"verified\"\n",
    "REQUIRE_AUTHOR_MATCH = True     # no verification without Author Match\n",
    "REQUIRE_TITLE_MATCH = True      # no verification without title reaching TITLE_MATCH_THRESHOLD\n",
    "REQUEST_TIMEOUT = 60\n",
    "SLEEP_BETWEEN_CALLS = 0.2       # be kind to APIs\n",
    "\n",
    "@dataclass\n",
    "class ParsedRef:\n",
    "    title: Optional[str]\n",
    "    year: Optional[int]\n",
    "    authors: List[str]\n",
    "    venue: Optional[str]\n",
    "    doi: Optional[str]\n",
    "    url: Optional[str] = None\n",
    "    raw: Optional[str] = None\n",
    "\n",
    "@dataclass\n",
    "class VerificationResult:\n",
    "    verified: bool\n",
    "    score: int\n",
    "    reason: str\n",
    "    matched_source: Optional[str] = None\n",
    "    matched_id: Optional[str] = None\n",
    "    matched_title: Optional[str] = None\n",
    "    matched_doi: Optional[str] = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b04722b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def grobid_extract_references(pdf_path: str) -> List[ParsedRef]:\n",
    "    with open(pdf_path, \"rb\") as f:\n",
    "        r = requests.post(\n",
    "            GROBID_URL,\n",
    "            files={\"input\": (os.path.basename(pdf_path), f, \"application/pdf\")},\n",
    "            timeout=REQUEST_TIMEOUT,\n",
    "        )\n",
    "    r.raise_for_status()\n",
    "    tei_xml = r.text.encode(\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "    root = etree.fromstring(tei_xml)\n",
    "    ns = {\"tei\": \"http://www.tei-c.org/ns/1.0\"}\n",
    "\n",
    "    refs = []\n",
    "    for bibl in root.xpath(\".//tei:listBibl/tei:biblStruct\", namespaces=ns):\n",
    "        title = _first_text(bibl.xpath(\".//tei:title[@level='a']/text()\", namespaces=ns)) \\\n",
    "                or _first_text(bibl.xpath(\".//tei:title/text()\", namespaces=ns))\n",
    "\n",
    "        year_txt = _first_text(bibl.xpath(\".//tei:date/@when\", namespaces=ns)) \\\n",
    "                   or _first_text(bibl.xpath(\".//tei:date/text()\", namespaces=ns))\n",
    "        year = _parse_year(year_txt)\n",
    "\n",
    "        doi = _first_text(bibl.xpath(\".//tei:idno[@type='DOI']/text()\", namespaces=ns))\n",
    "        if doi:\n",
    "            doi = doi.strip().lower()\n",
    "            doi = doi.replace(\"https://doi.org/\", \"\").replace(\"http://doi.org/\", \"\")\n",
    "\n",
    "        authors = []\n",
    "        for a in bibl.xpath(\".//tei:author\", namespaces=ns):\n",
    "            surname = _first_text(a.xpath(\".//tei:surname/text()\", namespaces=ns))\n",
    "            forename = _first_text(a.xpath(\".//tei:forename/text()\", namespaces=ns))\n",
    "            if surname and forename:\n",
    "                authors.append(f\"{surname}, {forename}\")\n",
    "            elif surname:\n",
    "                authors.append(surname)\n",
    "\n",
    "        venue = _first_text(bibl.xpath(\".//tei:monogr//tei:title/text()\", namespaces=ns))\n",
    "        \n",
    "        url = (_first_text(bibl.xpath(\".//tei:idno[@type='URI']/text()\", namespaces=ns)) or \\\n",
    "                _first_text(bibl.xpath(\".//tei:idno[@type='url']/text()\", namespaces=ns)) or \\\n",
    "                _first_text(bibl.xpath(\".//tei:ptr/@target\", namespaces=ns)))\n",
    "        if url:\n",
    "            url = url.strip()\n",
    "\n",
    "        # Sometimes Grobid provides an unstructured ref string:\n",
    "        raw = _first_text(bibl.xpath(\".//tei:note[@type='raw_reference']/text()\", namespaces=ns))\n",
    "\n",
    "        refs.append(ParsedRef(title=title, year=year, authors=authors, venue=venue, doi=doi, url=url, raw=raw))\n",
    "\n",
    "    return refs\n",
    "\n",
    "\n",
    "def verify_by_url(ref: ParsedRef) -> Optional[VerificationResult]:\n",
    "    if not ref.url or not ref.title:\n",
    "        return None\n",
    "\n",
    "    url = ref.url.strip()\n",
    "    if not url.lower().startswith((\"http://\", \"https://\")):\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        # Prefer GET (HEAD often blocked or lies)\n",
    "        r = requests.get(\n",
    "            url,\n",
    "            timeout=30,\n",
    "            allow_redirects=True,\n",
    "            headers={\n",
    "                \"User-Agent\": \"ref-checker/0.1 (+https://example.org; contact: you@example.com)\"\n",
    "            },\n",
    "        )\n",
    "        if r.status_code >= 400:\n",
    "            return VerificationResult(False, 0, f\"URL returned HTTP {r.status_code}\", matched_source=\"url\", matched_id=url)\n",
    "\n",
    "        ctype = (r.headers.get(\"Content-Type\") or \"\").lower()\n",
    "\n",
    "        # If the link points to a PDF, you could optionally treat “reachable PDF” as weak evidence,\n",
    "        # or even run Grobid on it later.\n",
    "        if \"application/pdf\" in ctype or url.lower().endswith(\".pdf\"):\n",
    "            return VerificationResult(\n",
    "                verified=True,\n",
    "                score=2,\n",
    "                reason=\"URL reachable and points to a PDF\",\n",
    "                matched_source=\"url\",\n",
    "                matched_id=r.url,\n",
    "                matched_title=None,\n",
    "            )\n",
    "\n",
    "        # Parse HTML title / meta\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "        candidates = []\n",
    "        if soup.title and soup.title.get_text(strip=True):\n",
    "            candidates.append(soup.title.get_text(strip=True))\n",
    "\n",
    "        og = soup.find(\"meta\", attrs={\"property\": \"og:title\"})\n",
    "        if og and og.get(\"content\"):\n",
    "            candidates.append(og[\"content\"].strip())\n",
    "\n",
    "        tw = soup.find(\"meta\", attrs={\"name\": \"twitter:title\"})\n",
    "        if tw and tw.get(\"content\"):\n",
    "            candidates.append(tw[\"content\"].strip())\n",
    "\n",
    "        h1 = soup.find(\"h1\")\n",
    "        if h1 and h1.get_text(strip=True):\n",
    "            candidates.append(h1.get_text(strip=True))\n",
    "\n",
    "        candidates = [c for c in candidates if c]\n",
    "        if not candidates:\n",
    "            return VerificationResult(False, 0, \"URL reachable but no title candidates found\", matched_source=\"url\", matched_id=r.url)\n",
    "\n",
    "        best = max(fuzz.token_set_ratio(ref.title, c) for c in candidates)\n",
    "        if best >= 80:\n",
    "            return VerificationResult(\n",
    "                verified=True,\n",
    "                score=3,\n",
    "                reason=f\"URL title match (score={best})\",\n",
    "                matched_source=\"url\",\n",
    "                matched_id=r.url,\n",
    "                matched_title=max(candidates, key=lambda c: fuzz.token_set_ratio(ref.title, c)),\n",
    "            )\n",
    "\n",
    "        return VerificationResult(\n",
    "            verified=False,\n",
    "            score=0,\n",
    "            reason=f\"URL reachable but title mismatch (best score={best})\",\n",
    "            matched_source=\"url\",\n",
    "            matched_id=r.url,\n",
    "            matched_title=max(candidates, key=lambda c: fuzz.token_set_ratio(ref.title, c)),\n",
    "        )\n",
    "\n",
    "    except requests.RequestException as e:\n",
    "        return VerificationResult(False, 0, f\"URL fetch failed: {e.__class__.__name__}\", matched_source=\"url\", matched_id=url)\n",
    "\n",
    "\n",
    "def verify_reference(ref: ParsedRef) -> VerificationResult:\n",
    "    # 1) DOI check (strongest)\n",
    "    if ref.doi:\n",
    "        ok, meta = crossref_lookup_doi(ref.doi)\n",
    "        if ok:\n",
    "            return VerificationResult(\n",
    "                verified=True,\n",
    "                score=10,\n",
    "                reason=\"DOI verified via Crossref\",\n",
    "                matched_source=\"crossref\",\n",
    "                matched_id=meta.get(\"DOI\"),\n",
    "                matched_title=_safe_title(meta),\n",
    "                matched_doi=meta.get(\"DOI\"),\n",
    "            )\n",
    "        # DOI present but not found is suspicious\n",
    "        # continue with title search as a fallback\n",
    "\n",
    "    # 2) Title search (OpenAlex + Crossref)\n",
    "    evidence_score = 0\n",
    "    reasons = []\n",
    "\n",
    "    best_match = None  # (source, id, title, doi, title_score, year_ok, author_ok)\n",
    "    if ref.title:\n",
    "        oa = openalex_search(ref)\n",
    "        if oa:\n",
    "            evidence_score += oa[\"evidence\"]\n",
    "            reasons.append(oa[\"reason\"])\n",
    "            best_match = oa[\"best_match\"]\n",
    "\n",
    "        cr = crossref_search(ref)\n",
    "        if cr:\n",
    "            evidence_score += cr[\"evidence\"]\n",
    "            reasons.append(cr[\"reason\"])\n",
    "            # Keep whichever match has better title similarity\n",
    "            if (best_match is None) or (cr[\"best_match\"][4] > best_match[4]):\n",
    "                best_match = cr[\"best_match\"]\n",
    "\n",
    "    if evidence_score >= MIN_EVIDENCE_SCORE and best_match:\n",
    "        source, mid, mtitle, mdoi, tscore, year_ok, author_ok = best_match\n",
    "        return VerificationResult(\n",
    "            verified=True,\n",
    "            score=evidence_score,\n",
    "            reason=\"; \".join(reasons),\n",
    "            matched_source=source,\n",
    "            matched_id=mid,\n",
    "            matched_title=mtitle,\n",
    "            matched_doi=mdoi,\n",
    "        )\n",
    "\n",
    "    # After DOI lookup fails (or after DB search fails), try URL check\n",
    "    url_result = verify_by_url(ref)\n",
    "    if url_result and url_result.verified:\n",
    "        return url_result\n",
    "\n",
    "    # 3) Not verified\n",
    "    why = \"No confident match found\"\n",
    "    if ref.title is None and ref.doi is None:\n",
    "        why = \"No DOI and title missing (cannot verify reliably)\"\n",
    "    elif ref.doi and not ref.title:\n",
    "        why = \"DOI not found and title missing\"\n",
    "\n",
    "    return VerificationResult(\n",
    "        verified=False,\n",
    "        score=evidence_score,\n",
    "        reason=why + ((\" | \" + \"; \".join(reasons)) if reasons else \"\"),\n",
    "    )\n",
    "\n",
    "\n",
    "def crossref_lookup_doi(doi: str) -> Tuple[bool, Dict[str, Any]]:\n",
    "    # Crossref works endpoint supports /works/{doi}\n",
    "    url = f\"{CROSSREF_WORKS}/{doi}\"\n",
    "    try:\n",
    "        r = requests.get(url, timeout=REQUEST_TIMEOUT, headers={\"User-Agent\": \"ref-checker/0.1 (mailto:you@example.com)\"})\n",
    "        if r.status_code == 200:\n",
    "            data = r.json()\n",
    "            return True, data.get(\"message\", {})\n",
    "        return False, {}\n",
    "    except requests.RequestException:\n",
    "        return False, {}\n",
    "\n",
    "\n",
    "def crossref_search(ref: ParsedRef) -> Optional[Dict[str, Any]]:\n",
    "    q = ref.title.strip()\n",
    "    params = {\"query.bibliographic\": q, \"rows\": 5}\n",
    "    try:\n",
    "        r = requests.get(CROSSREF_WORKS, params=params, timeout=REQUEST_TIMEOUT,\n",
    "                         headers={\"User-Agent\": \"ref-checker/0.1 (mailto:you@example.com)\"})\n",
    "        r.raise_for_status()\n",
    "        items = r.json().get(\"message\", {}).get(\"items\", [])\n",
    "    except requests.RequestException:\n",
    "        return None\n",
    "    finally:\n",
    "        time.sleep(SLEEP_BETWEEN_CALLS)\n",
    "\n",
    "    best = None\n",
    "    for it in items:\n",
    "        mtitle = _safe_title(it)\n",
    "        if not mtitle:\n",
    "            continue\n",
    "        tscore = fuzz.token_set_ratio(ref.title, mtitle)\n",
    "        year_ok = _year_matches(ref.year, it.get(\"issued\", {}))\n",
    "        author_ok = _author_overlap(ref.authors, it.get(\"author\", []))\n",
    "        # Hard gates (policy)\n",
    "        if REQUIRE_TITLE_MATCH and tscore < TITLE_MATCH_THRESHOLD:\n",
    "            continue\n",
    "        if REQUIRE_AUTHOR_MATCH and not author_ok:\n",
    "            continue\n",
    "        evidence = 0\n",
    "        if tscore >= TITLE_MATCH_THRESHOLD:\n",
    "            evidence += 1\n",
    "        if year_ok:\n",
    "            evidence += 1\n",
    "        if author_ok:\n",
    "            evidence += 1\n",
    "\n",
    "        cand = (\"crossref\", it.get(\"DOI\"), mtitle, it.get(\"DOI\"), tscore, year_ok, author_ok)\n",
    "        if best is None or cand[4] > best[4]:\n",
    "            best = cand\n",
    "\n",
    "    if not best:\n",
    "        return None\n",
    "\n",
    "    evidence = (1 if best[4] >= TITLE_MATCH_THRESHOLD else 0) + (1 if best[5] else 0) + (1 if best[6] else 0)\n",
    "    return {\n",
    "        \"evidence\": evidence,\n",
    "        \"reason\": f\"Crossref best title score={best[4]}, year_ok={best[5]}, author_ok={best[6]}\",\n",
    "        \"best_match\": best,\n",
    "    }\n",
    "\n",
    "\n",
    "def openalex_search(ref: ParsedRef) -> Optional[Dict[str, Any]]:\n",
    "    # OpenAlex: use filter=title.search: and optional year\n",
    "    params = {\n",
    "        \"search\": ref.title,\n",
    "        \"per-page\": 5,\n",
    "    }\n",
    "    try:\n",
    "        r = requests.get(OPENALEX_WORKS, params=params, timeout=REQUEST_TIMEOUT)\n",
    "        r.raise_for_status()\n",
    "        results = r.json().get(\"results\", [])\n",
    "    except requests.RequestException:\n",
    "        return None\n",
    "    finally:\n",
    "        time.sleep(SLEEP_BETWEEN_CALLS)\n",
    "\n",
    "    best = None\n",
    "    for it in results:\n",
    "        mtitle = it.get(\"title\")\n",
    "        if not mtitle:\n",
    "            continue\n",
    "        tscore = fuzz.token_set_ratio(ref.title, mtitle)\n",
    "        year_ok = (ref.year is None) or (it.get(\"publication_year\") == ref.year)\n",
    "        author_ok = _openalex_author_overlap(ref.authors, it.get(\"authorships\", []))\n",
    "        # Hard gates (policy)\n",
    "        if REQUIRE_TITLE_MATCH and tscore < TITLE_MATCH_THRESHOLD:\n",
    "            continue\n",
    "        if REQUIRE_AUTHOR_MATCH and not author_ok:\n",
    "            continue\n",
    "        evidence = 0\n",
    "        if tscore >= TITLE_MATCH_THRESHOLD:\n",
    "            evidence += 1\n",
    "        if year_ok:\n",
    "            evidence += 1\n",
    "        if author_ok:\n",
    "            evidence += 1\n",
    "\n",
    "        mid = it.get(\"id\")\n",
    "        doi = it.get(\"doi\")\n",
    "        if doi:\n",
    "            doi = doi.replace(\"https://doi.org/\", \"\").lower()\n",
    "\n",
    "        cand = (\"openalex\", mid, mtitle, doi, tscore, year_ok, author_ok)\n",
    "        if best is None or cand[4] > best[4]:\n",
    "            best = cand\n",
    "\n",
    "    if not best:\n",
    "        return None\n",
    "\n",
    "    evidence = (1 if best[4] >= TITLE_MATCH_THRESHOLD else 0) + (1 if best[5] else 0) + (1 if best[6] else 0)\n",
    "    return {\n",
    "        \"evidence\": evidence,\n",
    "        \"reason\": f\"OpenAlex best title score={best[4]}, year_ok={best[5]}, author_ok={best[6]}\",\n",
    "        \"best_match\": best,\n",
    "    }\n",
    "\n",
    "\n",
    "def analyze_file(pdf_dir: str, out_json: str = \"report.json\") -> Dict[str, Any]:\n",
    "    report = {\"files\": {}}\n",
    "\n",
    "    pdfs = [os.path.join(pdf_dir, f) for f in os.listdir(pdf_dir) if f.lower().endswith(\".pdf\")]\n",
    "    for pdf_path in tqdm(pdfs, desc=\"Processing PDFs\"):\n",
    "        filename = os.path.basename(pdf_path)\n",
    "        try:\n",
    "            refs = grobid_extract_references(pdf_path)\n",
    "        except Exception as e:\n",
    "            report[\"files\"][filename] = {\"error\": str(e), \"refs\": []}\n",
    "            continue\n",
    "\n",
    "        flagged = []\n",
    "        verified = []       \n",
    "        ref_results = []\n",
    "\n",
    "        for ref in refs:\n",
    "            vr = verify_reference(ref)\n",
    "            ref_results.append({\"ref\": asdict(ref), \"verification\": asdict(vr)})\n",
    "            if not vr.verified:\n",
    "                flagged.append({\"ref\": asdict(ref), \"why\": asdict(vr)})\n",
    "            else:\n",
    "                verified.append({\"ref\": asdict(ref), \"why\": asdict(vr)})\n",
    "                \n",
    "        report[\"files\"][filename] = {\n",
    "            \"num_refs\": len(refs),\n",
    "            \"num_unverified\": len(flagged),\n",
    "            \"unverified\": flagged[:],  # you can truncate if you want\n",
    "            \"verified\": verified[:],\n",
    "        }\n",
    "\n",
    "    with open(out_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(report, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    return report\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80551501",
   "metadata": {},
   "source": [
    "Here are some helper functions used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f40a42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------- helpers ----------\n",
    "\n",
    "def _first_text(items):\n",
    "    return items[0].strip() if items else None\n",
    "\n",
    "def _parse_year(s: Optional[str]) -> Optional[int]:\n",
    "    if not s:\n",
    "        return None\n",
    "    m = re.search(r\"(19|20)\\d{2}\", s)\n",
    "    return int(m.group(0)) if m else None\n",
    "\n",
    "def _safe_title(crossref_item: Dict[str, Any]) -> Optional[str]:\n",
    "    t = crossref_item.get(\"title\")\n",
    "    if isinstance(t, list) and t:\n",
    "        return t[0]\n",
    "    if isinstance(t, str):\n",
    "        return t\n",
    "    return None\n",
    "\n",
    "def _year_matches(ref_year: Optional[int], issued: Dict[str, Any]) -> bool:\n",
    "    if ref_year is None:\n",
    "        return True\n",
    "    parts = issued.get(\"date-parts\")\n",
    "    if not parts or not parts[0]:\n",
    "        return False\n",
    "    return parts[0][0] == ref_year\n",
    "\n",
    "def _author_overlap(ref_authors: List[str], crossref_authors: List[Dict[str, Any]]) -> bool:\n",
    "    if not ref_authors or not crossref_authors:\n",
    "        return False\n",
    "    ref_surnames = {a.split(\",\")[0].strip().lower() for a in ref_authors if a}\n",
    "    cr_surnames = {a.get(\"family\", \"\").strip().lower() for a in crossref_authors if a.get(\"family\")}\n",
    "    return len(ref_surnames & cr_surnames) >= 1\n",
    "\n",
    "def _openalex_author_overlap(ref_authors: List[str], authorships: List[Dict[str, Any]]) -> bool:\n",
    "    if not ref_authors or not authorships:\n",
    "        return False\n",
    "    ref_surnames = {a.split(\",\")[0].strip().lower() for a in ref_authors if a}\n",
    "    oa_surnames = set()\n",
    "    for au in authorships:\n",
    "        name = (au.get(\"author\") or {}).get(\"display_name\") or \"\"\n",
    "        # last token as surname-ish heuristic\n",
    "        parts = name.split()\n",
    "        if parts:\n",
    "            oa_surnames.add(parts[-1].strip().lower())\n",
    "    return len(ref_surnames & oa_surnames) >= 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37683f31",
   "metadata": {},
   "source": [
    "Now we run the code. Here we assume that there is only one file in `PDF_FOLDER`!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ffdf86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs: 100%|██████████| 1/1 [00:52<00:00, 52.59s/it]\n"
     ]
    }
   ],
   "source": [
    "pdf_dir = PDF_FOLDER\n",
    "report = {\"files\": {}}\n",
    "pdfs = [os.path.join(pdf_dir, f) for f in os.listdir(pdf_dir) if f.lower().endswith(\".pdf\")]\n",
    "for pdf_path in tqdm(pdfs, desc=\"Processing PDFs\"):\n",
    "    filename = os.path.basename(pdf_path)\n",
    "    try:\n",
    "        refs = grobid_extract_references(pdf_path)\n",
    "    except Exception as e:\n",
    "        report[\"files\"][filename] = {\"error\": str(e), \"refs\": []}\n",
    "        continue\n",
    "\n",
    "    flagged = []\n",
    "    verified = []       \n",
    "    ref_results = []\n",
    "\n",
    "    for ref in refs:\n",
    "        vr = verify_reference(ref)\n",
    "        ref_results.append({\"ref\": asdict(ref), \"verification\": asdict(vr)})\n",
    "        if not vr.verified:\n",
    "            flagged.append({\"ref\": asdict(ref), \"why\": asdict(vr)})\n",
    "        else:\n",
    "            verified.append({\"ref\": asdict(ref), \"why\": asdict(vr)})\n",
    "            \n",
    "    report[\"files\"][filename] = {\n",
    "        \"num_refs\": len(refs),\n",
    "        \"num_unverified\": len(flagged),\n",
    "        \"unverified\": flagged[:],  # you can truncate if you want\n",
    "        \"verified\": verified[:],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dc0373",
   "metadata": {},
   "source": [
    "These are the papers identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71a553b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ParsedRef(title='Learning to teach', year=1991, authors=['Arends, R', 'Castle, S'], venue='Learning to teach', doi=None, url=None, raw=None),\n",
       " ParsedRef(title='Teaching for Quality Learning at University', year=2011, authors=['Biggs, J', 'Tang, C'], venue='Teaching for Quality Learning at University', doi=None, url=None, raw=None),\n",
       " ParsedRef(title='Assessment and classroom learning', year=1998, authors=['Black, P', 'Wiliam, D'], venue='Assessment and classroom learning', doi=None, url=None, raw=None),\n",
       " ParsedRef(title='Taxonomy of Educational Objectives, Handbook I: Cognitive Domain', year=1956, authors=['Bloom, B'], venue='Taxonomy of Educational Objectives, Handbook I: Cognitive Domain', doi=None, url=None, raw=None),\n",
       " ParsedRef(title='Universal Design for Learning Guidelines', year=2018, authors=[], venue='Universal Design for Learning Guidelines', doi=None, url=None, raw=None),\n",
       " ParsedRef(title='Authentic learning environments. Handbook of research on educational communications and technology', year=2013, authors=['Herrington, J', 'Reeves, T', 'Oliver, R'], venue='Authentic learning environments. Handbook of research on educational communications and technology', doi=None, url=None, raw=None),\n",
       " ParsedRef(title='Cooperative learning: Improving university instruction by basing practice on validated theory', year=2014, authors=['Johnson, D', 'Johnson, R', 'Smith, K'], venue='Journal on Excellence in University Teaching', doi=None, url=None, raw=None),\n",
       " ParsedRef(title='Constructivism in Education: Opinions and Second Opinions on Controversial Issues. National Society for the Study of Education', year=2000, authors=['Phillips, D'], venue='Constructivism in Education: Opinions and Second Opinions on Controversial Issues. National Society for the Study of Education', doi=None, url=None, raw=None),\n",
       " ParsedRef(title=\"Relations between teachers' approaches to teaching and students' approaches to learning\", year=1999, authors=['Trigwell, K', 'Prosser, M', 'Waterhouse, F'], venue='Higher Education', doi=None, url=None, raw=None),\n",
       " ParsedRef(title=\"The interplay between teachers' approaches to teaching, students' approaches to learning and learning outcomes: a qualitative multi-case study\", year=2018, authors=['Uiboleht, K', 'Karm, M', 'Postareff, L'], venue='Learning Environments Research', doi=None, url=None, raw=None),\n",
       " ParsedRef(title='The role of self-confidence in learning to teach in higher education', year=2013, authors=['Sadler, I'], venue='Innovations in Education and Teaching International', doi='10.1080/14703297.2012.760777', url=None, raw=None),\n",
       " ParsedRef(title='Formative self-and peer assessment for improved student learning: the crucial factors of design, teacher participation and feedback', year=2018, authors=['Wanner, T', 'Palmer, E'], venue='Assessment & Evaluation in Higher Education', doi=None, url=None, raw=None),\n",
       " ParsedRef(title='Economic reasoning: Turning myth into reality', year=1987, authors=['Wentworth, D'], venue='Theory into Practice', doi=None, url=None, raw=None)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d430cb",
   "metadata": {},
   "source": [
    "This is the report listing the unverified and verified papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f83bbe27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'files': {'Writing documents_YU Joyce_finalversion.pdf': {'num_refs': 13,\n",
       "   'num_unverified': 5,\n",
       "   'unverified': [{'ref': {'title': 'Learning to teach',\n",
       "      'year': 1991,\n",
       "      'authors': ['Arends, R', 'Castle, S'],\n",
       "      'venue': 'Learning to teach',\n",
       "      'doi': None,\n",
       "      'url': None,\n",
       "      'raw': None},\n",
       "     'why': {'verified': False,\n",
       "      'score': 0,\n",
       "      'reason': 'No confident match found',\n",
       "      'matched_source': None,\n",
       "      'matched_id': None,\n",
       "      'matched_title': None,\n",
       "      'matched_doi': None}},\n",
       "    {'ref': {'title': 'Teaching for Quality Learning at University',\n",
       "      'year': 2011,\n",
       "      'authors': ['Biggs, J', 'Tang, C'],\n",
       "      'venue': 'Teaching for Quality Learning at University',\n",
       "      'doi': None,\n",
       "      'url': None,\n",
       "      'raw': None},\n",
       "     'why': {'verified': False,\n",
       "      'score': 0,\n",
       "      'reason': 'No confident match found',\n",
       "      'matched_source': None,\n",
       "      'matched_id': None,\n",
       "      'matched_title': None,\n",
       "      'matched_doi': None}},\n",
       "    {'ref': {'title': 'Assessment and classroom learning',\n",
       "      'year': 1998,\n",
       "      'authors': ['Black, P', 'Wiliam, D'],\n",
       "      'venue': 'Assessment and classroom learning',\n",
       "      'doi': None,\n",
       "      'url': None,\n",
       "      'raw': None},\n",
       "     'why': {'verified': False,\n",
       "      'score': 0,\n",
       "      'reason': 'No confident match found',\n",
       "      'matched_source': None,\n",
       "      'matched_id': None,\n",
       "      'matched_title': None,\n",
       "      'matched_doi': None}},\n",
       "    {'ref': {'title': 'Universal Design for Learning Guidelines',\n",
       "      'year': 2018,\n",
       "      'authors': [],\n",
       "      'venue': 'Universal Design for Learning Guidelines',\n",
       "      'doi': None,\n",
       "      'url': None,\n",
       "      'raw': None},\n",
       "     'why': {'verified': False,\n",
       "      'score': 0,\n",
       "      'reason': 'No confident match found',\n",
       "      'matched_source': None,\n",
       "      'matched_id': None,\n",
       "      'matched_title': None,\n",
       "      'matched_doi': None}},\n",
       "    {'ref': {'title': 'Authentic learning environments. Handbook of research on educational communications and technology',\n",
       "      'year': 2013,\n",
       "      'authors': ['Herrington, J', 'Reeves, T', 'Oliver, R'],\n",
       "      'venue': 'Authentic learning environments. Handbook of research on educational communications and technology',\n",
       "      'doi': None,\n",
       "      'url': None,\n",
       "      'raw': None},\n",
       "     'why': {'verified': False,\n",
       "      'score': 0,\n",
       "      'reason': 'No confident match found',\n",
       "      'matched_source': None,\n",
       "      'matched_id': None,\n",
       "      'matched_title': None,\n",
       "      'matched_doi': None}}],\n",
       "   'verified': [{'ref': {'title': 'Taxonomy of Educational Objectives, Handbook I: Cognitive Domain',\n",
       "      'year': 1956,\n",
       "      'authors': ['Bloom, B'],\n",
       "      'venue': 'Taxonomy of Educational Objectives, Handbook I: Cognitive Domain',\n",
       "      'doi': None,\n",
       "      'url': None,\n",
       "      'raw': None},\n",
       "     'why': {'verified': True,\n",
       "      'score': 4,\n",
       "      'reason': 'OpenAlex best title score=98.4375, year_ok=False, author_ok=True; Crossref best title score=98.4375, year_ok=False, author_ok=True',\n",
       "      'matched_source': 'openalex',\n",
       "      'matched_id': 'https://openalex.org/W1622896514',\n",
       "      'matched_title': 'Taxonomy of Educational Objectives. Handbook I: Cognitive Domain',\n",
       "      'matched_doi': None}},\n",
       "    {'ref': {'title': 'Cooperative learning: Improving university instruction by basing practice on validated theory',\n",
       "      'year': 2014,\n",
       "      'authors': ['Johnson, D', 'Johnson, R', 'Smith, K'],\n",
       "      'venue': 'Journal on Excellence in University Teaching',\n",
       "      'doi': None,\n",
       "      'url': None,\n",
       "      'raw': None},\n",
       "     'why': {'verified': True,\n",
       "      'score': 3,\n",
       "      'reason': 'OpenAlex best title score=91.97860962566845, year_ok=True, author_ok=True',\n",
       "      'matched_source': 'openalex',\n",
       "      'matched_id': 'https://openalex.org/W2151436803',\n",
       "      'matched_title': 'Cooperative Learning: Improving University Instruction by Basing Practice on Validated Theory.',\n",
       "      'matched_doi': None}},\n",
       "    {'ref': {'title': 'Constructivism in Education: Opinions and Second Opinions on Controversial Issues. National Society for the Study of Education',\n",
       "      'year': 2000,\n",
       "      'authors': ['Phillips, D'],\n",
       "      'venue': 'Constructivism in Education: Opinions and Second Opinions on Controversial Issues. National Society for the Study of Education',\n",
       "      'doi': None,\n",
       "      'url': None,\n",
       "      'raw': None},\n",
       "     'why': {'verified': True,\n",
       "      'score': 3,\n",
       "      'reason': 'OpenAlex best title score=95.53571428571429, year_ok=True, author_ok=True',\n",
       "      'matched_source': 'openalex',\n",
       "      'matched_id': 'https://openalex.org/W63321254',\n",
       "      'matched_title': 'Constructivism in Education: Opinions and Second Opinions on Controversial Issues. Ninety-Ninth Yearbook of the National Society for the Study of Education.',\n",
       "      'matched_doi': None}},\n",
       "    {'ref': {'title': \"Relations between teachers' approaches to teaching and students' approaches to learning\",\n",
       "      'year': 1999,\n",
       "      'authors': ['Trigwell, K', 'Prosser, M', 'Waterhouse, F'],\n",
       "      'venue': 'Higher Education',\n",
       "      'doi': None,\n",
       "      'url': None,\n",
       "      'raw': None},\n",
       "     'why': {'verified': True,\n",
       "      'score': 6,\n",
       "      'reason': 'OpenAlex best title score=100.0, year_ok=True, author_ok=True; Crossref best title score=100.0, year_ok=True, author_ok=True',\n",
       "      'matched_source': 'openalex',\n",
       "      'matched_id': 'https://openalex.org/W1512850292',\n",
       "      'matched_title': \"Relations between teachers' approaches to teaching and students' approaches to learning\",\n",
       "      'matched_doi': '10.1023/a:1003548313194'}},\n",
       "    {'ref': {'title': \"The interplay between teachers' approaches to teaching, students' approaches to learning and learning outcomes: a qualitative multi-case study\",\n",
       "      'year': 2018,\n",
       "      'authors': ['Uiboleht, K', 'Karm, M', 'Postareff, L'],\n",
       "      'venue': 'Learning Environments Research',\n",
       "      'doi': None,\n",
       "      'url': None,\n",
       "      'raw': None},\n",
       "     'why': {'verified': True,\n",
       "      'score': 6,\n",
       "      'reason': 'OpenAlex best title score=98.31932773109244, year_ok=True, author_ok=True; Crossref best title score=98.31932773109244, year_ok=True, author_ok=True',\n",
       "      'matched_source': 'openalex',\n",
       "      'matched_id': 'https://openalex.org/W2783943498',\n",
       "      'matched_title': 'The interplay between teachers’ approaches to teaching, students’ approaches to learning and learning outcomes: a qualitative multi-case study',\n",
       "      'matched_doi': '10.1007/s10984-018-9257-1'}},\n",
       "    {'ref': {'title': 'The role of self-confidence in learning to teach in higher education',\n",
       "      'year': 2013,\n",
       "      'authors': ['Sadler, I'],\n",
       "      'venue': 'Innovations in Education and Teaching International',\n",
       "      'doi': '10.1080/14703297.2012.760777',\n",
       "      'url': None,\n",
       "      'raw': None},\n",
       "     'why': {'verified': True,\n",
       "      'score': 10,\n",
       "      'reason': 'DOI verified via Crossref',\n",
       "      'matched_source': 'crossref',\n",
       "      'matched_id': '10.1080/14703297.2012.760777',\n",
       "      'matched_title': 'The role of self-confidence in learning to teach in higher education',\n",
       "      'matched_doi': '10.1080/14703297.2012.760777'}},\n",
       "    {'ref': {'title': 'Formative self-and peer assessment for improved student learning: the crucial factors of design, teacher participation and feedback',\n",
       "      'year': 2018,\n",
       "      'authors': ['Wanner, T', 'Palmer, E'],\n",
       "      'venue': 'Assessment & Evaluation in Higher Education',\n",
       "      'doi': None,\n",
       "      'url': None,\n",
       "      'raw': None},\n",
       "     'why': {'verified': True,\n",
       "      'score': 6,\n",
       "      'reason': 'OpenAlex best title score=100.0, year_ok=True, author_ok=True; Crossref best title score=100.0, year_ok=True, author_ok=True',\n",
       "      'matched_source': 'openalex',\n",
       "      'matched_id': 'https://openalex.org/W2784565404',\n",
       "      'matched_title': 'Formative self-and peer assessment for improved student learning: the crucial factors of design, teacher participation and feedback',\n",
       "      'matched_doi': '10.1080/02602938.2018.1427698'}},\n",
       "    {'ref': {'title': 'Economic reasoning: Turning myth into reality',\n",
       "      'year': 1987,\n",
       "      'authors': ['Wentworth, D'],\n",
       "      'venue': 'Theory into Practice',\n",
       "      'doi': None,\n",
       "      'url': None,\n",
       "      'raw': None},\n",
       "     'why': {'verified': True,\n",
       "      'score': 6,\n",
       "      'reason': 'OpenAlex best title score=100.0, year_ok=True, author_ok=True; Crossref best title score=100.0, year_ok=True, author_ok=True',\n",
       "      'matched_source': 'openalex',\n",
       "      'matched_id': 'https://openalex.org/W2051325406',\n",
       "      'matched_title': 'Economic reasoning: Turning myth into reality',\n",
       "      'matched_doi': '10.1080/00405848709543270'}}]}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "532b7d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ParsedRef(title='How immigration is changing the economies of rich countries', year=2024, authors=[], venue='The Economist', doi=None, url=None, raw=None),\n",
       " ParsedRef(title=None, year=2025, authors=[], venue=None, doi=None, url='https://www.economist.com/', raw=None),\n",
       " ParsedRef(title='The Economic Impact of Immigration', year=2023, authors=['Peri, G'], venue='Journal of Economic Perspectives', doi=None, url=None, raw=None),\n",
       " ParsedRef(title='Ageing Japan needs a drastic shift in migration policy', year=2025, authors=[], venue='Ageing Japan needs a drastic shift in migration policy', doi=None, url='https://www.oxfordeconomics.com/resource/ageing-japan-needs-a-drastic-shift-in-migration-policy/', raw=None),\n",
       " ParsedRef(title='The Fiscal Impact of Immigration in the UK -Migration Observatory, Migration Observatory', year=2024, authors=['Vargas-Silva, C', 'Sumption, M', 'Walsh, P'], venue='The Fiscal Impact of Immigration in the UK -Migration Observatory, Migration Observatory', doi=None, url='https://migrationobservatory.ox.ac.uk/resources/briefings/the-fiscal-impact-of-immigration-in-the-uk/', raw=None),\n",
       " ParsedRef(title='Net migration forecast and its impact on the economy', year=2024, authors=['Obr'], venue='Net migration forecast and its impact on the economy', doi=None, url='https://obr.uk/box/net-migration-forecast-and-its-impact-on-the-economy/', raw=None),\n",
       " ParsedRef(title='Immigration and labour productivity: A comparative effect', year=2025, authors=['Gnimassoun, B'], venue='World Development', doi=None, url='https://www.sciencedirect.com/science/article/pii/S0305750X25000038', raw=None),\n",
       " ParsedRef(title='The economics of Canadian immigration levels', year=2025, authors=['Doyle, M', 'Skuterud, M', 'Worswick, C'], venue=\"Canadian Journal of Economics/Revue canadienne d'économique\", doi=None, url=None, raw=None)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grobid_extract_references(pdf_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3819773e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs: 100%|██████████| 1/1 [00:01<00:00,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote report_file.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "analyze_file(PDF_FOLDER, out_json=\"report_file.json\")\n",
    "print(\"Wrote report_file.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
